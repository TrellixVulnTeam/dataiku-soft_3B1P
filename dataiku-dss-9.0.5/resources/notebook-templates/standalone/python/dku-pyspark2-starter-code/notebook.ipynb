{
 "cells": [
  {
   "cell_type": "code", "metadata":{}, "outputs" : [], "execution_count" : null,
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code", "metadata" : {}, "outputs" :[], "execution_count" : null,
   "source": [
    "import dataiku\nimport dataiku.spark as dkuspark\nimport pyspark\nfrom pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code", "metadata" : {}, "outputs" :[], "execution_count" : null,
   "source": [
      "# Load PySpark\nsc = pyspark.SparkContext.getOrCreate()\nsqlContext = SQLContext(sc)"
    ]
  },
  {
   "cell_type": "code", "metadata" : {}, "outputs" :[], "execution_count" : null,
   "source": [
      "# Example: Read the descriptor of a Dataiku dataset\nmydataset = dataiku.Dataset(\"mydataset\")\n# And read it as a Spark dataframe\ndf = dkuspark.get_dataframe(sqlContext, mydataset)"
    ]
  },
  {
   "cell_type": "code", "metadata" : {}, "outputs" :[], "execution_count" : null,
   "source": [
      "# Example: Get the count of records in the dataframe\n",
      "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name" : "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}